{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b9845fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset test입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0714ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import heapq\n",
    "import pickle\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tail = 30\n",
    "parallel = 1024\n",
    "topn = 20\n",
    "ops_weights = np.array([1.0, 6.0, 3.0])\n",
    "OP_WEIGHT = 0; TIME_WEIGHT = 1\n",
    "parallel = 1024\n",
    "test_ops_weights = np.array([1.0, 6.0, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f367e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/ghtyu/OneDrive/Desktop/OTTO/otto_data/LB_574_Dataset_Tony'\n",
    "df = pd.read_csv(os.path.join(path,\"train.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(path,\"test.csv\"))\n",
    "df = pd.concat([df, df_test]).reset_index(drop = True)\n",
    "npz = np.load(os.path.join(path,\"train.npz\"))\n",
    "npz_test = np.load(os.path.join(path,\"test.npz\"))\n",
    "aids = np.concatenate([npz['aids'], npz_test['aids']])\n",
    "ts = np.concatenate([npz['ts'], npz_test['ts']])\n",
    "ops = np.concatenate([npz['ops'], npz_test['ops']])\n",
    "\n",
    "df[\"idx\"] = np.cumsum(df.length) - df.length  # length\n",
    "df[\"end_time\"] = df.start_time + ts[df.idx + df.length - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0974236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>start_time</th>\n",
       "      <th>length</th>\n",
       "      <th>idx</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>1661684983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>32</td>\n",
       "      <td>276</td>\n",
       "      <td>1661714854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>33</td>\n",
       "      <td>308</td>\n",
       "      <td>1661714215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>226</td>\n",
       "      <td>341</td>\n",
       "      <td>1661109666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>19</td>\n",
       "      <td>567</td>\n",
       "      <td>1661586681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>15</td>\n",
       "      <td>586</td>\n",
       "      <td>1660348787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>204</td>\n",
       "      <td>601</td>\n",
       "      <td>1661549531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>23</td>\n",
       "      <td>805</td>\n",
       "      <td>1660538518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>4</td>\n",
       "      <td>828</td>\n",
       "      <td>1659304839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>7</td>\n",
       "      <td>832</td>\n",
       "      <td>1659648132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>6</td>\n",
       "      <td>839</td>\n",
       "      <td>1661633426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>93</td>\n",
       "      <td>845</td>\n",
       "      <td>1661006377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>5</td>\n",
       "      <td>938</td>\n",
       "      <td>1661029692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>81</td>\n",
       "      <td>943</td>\n",
       "      <td>1661685031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>382</td>\n",
       "      <td>1024</td>\n",
       "      <td>1661708736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>86</td>\n",
       "      <td>1406</td>\n",
       "      <td>1661625420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>12</td>\n",
       "      <td>1492</td>\n",
       "      <td>1659379224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>91</td>\n",
       "      <td>1504</td>\n",
       "      <td>1661453893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>26</td>\n",
       "      <td>1595</td>\n",
       "      <td>1660172244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>112</td>\n",
       "      <td>1621</td>\n",
       "      <td>1661716367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>7</td>\n",
       "      <td>1733</td>\n",
       "      <td>1661350999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>372</td>\n",
       "      <td>1740</td>\n",
       "      <td>1661371674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>14</td>\n",
       "      <td>2112</td>\n",
       "      <td>1660218901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>108</td>\n",
       "      <td>2126</td>\n",
       "      <td>1661665910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>108</td>\n",
       "      <td>2234</td>\n",
       "      <td>1661126018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>261</td>\n",
       "      <td>2342</td>\n",
       "      <td>1661722815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>43</td>\n",
       "      <td>2603</td>\n",
       "      <td>1660811509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>7</td>\n",
       "      <td>2646</td>\n",
       "      <td>1660656336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>292</td>\n",
       "      <td>2653</td>\n",
       "      <td>1661634995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>76</td>\n",
       "      <td>2945</td>\n",
       "      <td>1661119746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>24</td>\n",
       "      <td>3021</td>\n",
       "      <td>1659346523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>6</td>\n",
       "      <td>3045</td>\n",
       "      <td>1659305184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>126</td>\n",
       "      <td>3051</td>\n",
       "      <td>1661123718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>88</td>\n",
       "      <td>3177</td>\n",
       "      <td>1661443177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>115</td>\n",
       "      <td>3265</td>\n",
       "      <td>1661285263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>231</td>\n",
       "      <td>3380</td>\n",
       "      <td>1661710374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>213</td>\n",
       "      <td>3611</td>\n",
       "      <td>1661672467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>267</td>\n",
       "      <td>3824</td>\n",
       "      <td>1661723991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>151</td>\n",
       "      <td>4091</td>\n",
       "      <td>1659896366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>185</td>\n",
       "      <td>4242</td>\n",
       "      <td>1661697936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>310</td>\n",
       "      <td>4427</td>\n",
       "      <td>1661722079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>123</td>\n",
       "      <td>4737</td>\n",
       "      <td>1661723926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>129</td>\n",
       "      <td>4860</td>\n",
       "      <td>1659967903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>3</td>\n",
       "      <td>4989</td>\n",
       "      <td>1659568912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>151</td>\n",
       "      <td>4992</td>\n",
       "      <td>1661602118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>3</td>\n",
       "      <td>5143</td>\n",
       "      <td>1659305178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>24</td>\n",
       "      <td>5146</td>\n",
       "      <td>1661636864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>63</td>\n",
       "      <td>5170</td>\n",
       "      <td>1661575208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>376</td>\n",
       "      <td>5233</td>\n",
       "      <td>1661371174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>230</td>\n",
       "      <td>5609</td>\n",
       "      <td>1661377775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session  start_time  length   idx    end_time\n",
       "0         0  1659304800     276     0  1661684983\n",
       "1         1  1659304800      32   276  1661714854\n",
       "2         2  1659304800      33   308  1661714215\n",
       "3         3  1659304800     226   341  1661109666\n",
       "4         4  1659304800      19   567  1661586681\n",
       "5         5  1659304800      15   586  1660348787\n",
       "6         6  1659304800     204   601  1661549531\n",
       "7         7  1659304800      23   805  1660538518\n",
       "8         8  1659304800       4   828  1659304839\n",
       "9         9  1659304800       7   832  1659648132\n",
       "10       10  1659304800       6   839  1661633426\n",
       "11       11  1659304800      93   845  1661006377\n",
       "12       12  1659304800       5   938  1661029692\n",
       "13       13  1659304800      81   943  1661685031\n",
       "14       14  1659304800     382  1024  1661708736\n",
       "15       15  1659304800      86  1406  1661625420\n",
       "16       16  1659304800      12  1492  1659379224\n",
       "17       17  1659304800      91  1504  1661453893\n",
       "18       18  1659304800      26  1595  1660172244\n",
       "19       19  1659304800     112  1621  1661716367\n",
       "20       20  1659304800       7  1733  1661350999\n",
       "21       21  1659304800     372  1740  1661371674\n",
       "22       22  1659304800      14  2112  1660218901\n",
       "23       23  1659304800     108  2126  1661665910\n",
       "24       24  1659304800     108  2234  1661126018\n",
       "25       25  1659304800     261  2342  1661722815\n",
       "26       26  1659304800      43  2603  1660811509\n",
       "27       27  1659304800       7  2646  1660656336\n",
       "28       28  1659304800     292  2653  1661634995\n",
       "29       29  1659304800      76  2945  1661119746\n",
       "30       30  1659304800      24  3021  1659346523\n",
       "31       31  1659304800       6  3045  1659305184\n",
       "32       32  1659304800     126  3051  1661123718\n",
       "33       33  1659304800      88  3177  1661443177\n",
       "34       34  1659304800     115  3265  1661285263\n",
       "35       35  1659304800     231  3380  1661710374\n",
       "36       36  1659304800     213  3611  1661672467\n",
       "37       37  1659304800     267  3824  1661723991\n",
       "38       38  1659304800     151  4091  1659896366\n",
       "39       39  1659304800     185  4242  1661697936\n",
       "40       40  1659304800     310  4427  1661722079\n",
       "41       41  1659304800     123  4737  1661723926\n",
       "42       42  1659304800     129  4860  1659967903\n",
       "43       43  1659304800       3  4989  1659568912\n",
       "44       44  1659304800     151  4992  1661602118\n",
       "45       45  1659304800       3  5143  1659305178\n",
       "46       46  1659304800      24  5146  1661636864\n",
       "47       47  1659304800      63  5170  1661575208\n",
       "48       48  1659304800     376  5233  1661371174\n",
       "49       49  1659304800     230  5609  1661377775"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)  # session / start_time / length / idx / end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ecd4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pair dict {(aid1, aid2): weight} for each session\n",
    "# The maximum time span between two points is 1 day = 24 * 60 * 60 sec\n",
    "@nb.jit(nopython = True, cache = True)\n",
    "def get_single_pairs(pairs, aids, ts, ops, idx, length, start_time, ops_weights, mode):\n",
    "    max_idx = idx + length\n",
    "    min_idx = max(max_idx - tail, idx)\n",
    "    for i in range(min_idx, max_idx):\n",
    "        for j in range(i + 1, max_idx):\n",
    "            if ts[j] - ts[i] >= 24 * 60 * 60: break\n",
    "            if aids[i] == aids[j]: continue\n",
    "            if mode == OP_WEIGHT:\n",
    "                w1 = ops_weights[ops[j]]\n",
    "                w2 = ops_weights[ops[i]]\n",
    "            elif mode == TIME_WEIGHT:\n",
    "                w1 = 1 + 3 * (ts[i] + start_time - 1659304800) / (1662328791 - 1659304800)\n",
    "                w2 = 1 + 3 * (ts[j] + start_time - 1659304800) / (1662328791 - 1659304800)\n",
    "            pairs[(aids[i], aids[j])] = w1\n",
    "            pairs[(aids[j], aids[i])] = w2\n",
    "\n",
    "# get pair dict of each session in parallel\n",
    "# merge pairs into a nested dict format (cnt)\n",
    "@nb.jit(nopython = True, parallel = True, cache = True)\n",
    "def get_pairs(aids, ts, ops, row, cnts, ops_weights, mode):\n",
    "    par_n = len(row)\n",
    "    pairs = [{(0, 0): 0.0 for _ in range(0)} for _ in range(par_n)]\n",
    "    for par_i in nb.prange(par_n):\n",
    "        _, idx, length, start_time = row[par_i]\n",
    "        get_single_pairs(pairs[par_i], aids, ts, ops, idx, length, start_time, ops_weights, mode)\n",
    "    for par_i in range(par_n):\n",
    "        for (aid1, aid2), w in pairs[par_i].items():\n",
    "            if aid1 not in cnts: cnts[aid1] = {0: 0.0 for _ in range(0)}\n",
    "            cnt = cnts[aid1]\n",
    "            if aid2 not in cnt: cnt[aid2] = 0.0\n",
    "            cnt[aid2] += w\n",
    "    \n",
    "# util function to get most common keys from a counter dict using min-heap\n",
    "# overwrite == 1 means the later item with equal weight is more important\n",
    "# otherwise, means the former item with equal weight is more important\n",
    "# the result is ordered from higher weight to lower weight\n",
    "@nb.jit(nopython = True, cache = True)\n",
    "def heap_topk(cnt, overwrite, cap):\n",
    "    q = [(0.0, 0, 0) for _ in range(0)]\n",
    "    for i, (k, n) in enumerate(cnt.items()):\n",
    "        if overwrite == 1:\n",
    "            heapq.heappush(q, (n, i, k))   # heapq??\n",
    "        else:\n",
    "            heapq.heappush(q, (n, -i, k))\n",
    "        if len(q) > cap:\n",
    "            heapq.heappop(q)\n",
    "    return [heapq.heappop(q)[2] for _ in range(len(q))][::-1]\n",
    "   \n",
    "# save top-k aid2 for each aid1's cnt\n",
    "@nb.jit(nopython = True, cache = True)\n",
    "def get_topk(cnts, topk, k):\n",
    "    for aid1, cnt in cnts.items():\n",
    "        topk[aid1] = np.array(heap_topk(cnt, 1, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59677c83",
   "metadata": {},
   "source": [
    "numba function speed up python code and part of numpy code.\n",
    "as I know, when we ran numba function, python interpreter does not step in but compiler do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "959727ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86aa006a950b45dcbaf9609bfdf9e2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d004f81dfba41148b3cdba003a6c342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topks = {}\n",
    "\n",
    "# for two modes\n",
    "for mode in [OP_WEIGHT, TIME_WEIGHT]:\n",
    "    # get nested counter\n",
    "    cnts = nb.typed.Dict.empty(\n",
    "        key_type = nb.types.int64,\n",
    "        value_type = nb.typeof(nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)))\n",
    "    max_idx = len(df)\n",
    "    for idx in tqdm(range(0, max_idx, parallel)):\n",
    "        row = df.iloc[idx:min(idx + parallel, max_idx)][['session', 'idx', 'length', 'start_time']].values\n",
    "        get_pairs(aids, ts, ops, row, cnts, ops_weights, mode)\n",
    "\n",
    "    # get topk from counter\n",
    "    topk = nb.typed.Dict.empty(\n",
    "            key_type = nb.types.int64,\n",
    "            value_type = nb.types.int64[:])\n",
    "    get_topk(cnts, topk, topn)\n",
    "\n",
    "    del cnts; gc.collect()\n",
    "    topks[mode] = topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2beff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython = True, cache = True)\n",
    "def inference_(aids, ops, row, result, topk, test_ops_weights, seq_weight):\n",
    "    for session, idx, length in row:\n",
    "        unique_aids = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "        cnt = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "        \n",
    "        candidates = aids[idx:idx + length][::-1]\n",
    "        candidates_ops = ops[idx:idx + length][::-1]\n",
    "        for a in candidates:\n",
    "            unique_aids[a] = 0\n",
    "                \n",
    "        if len(unique_aids) >= 20:\n",
    "            sequence_weight = np.power(2, np.linspace(seq_weight, 1, len(candidates)))[::-1] - 1\n",
    "            for a, op, w in zip(candidates, candidates_ops, sequence_weight):\n",
    "                if a not in cnt: cnt[a] = 0\n",
    "                cnt[a] += w * test_ops_weights[op]\n",
    "            result_candidates = heap_topk(cnt, 0, 20)\n",
    "        else:\n",
    "            result_candidates = list(unique_aids)\n",
    "            for a in result_candidates:\n",
    "                if a not in topk: continue\n",
    "                for b in topk[a]:\n",
    "                    if b in unique_aids: continue\n",
    "                    if b not in cnt: cnt[b] = 0\n",
    "                    cnt[b] += 1\n",
    "            result_candidates.extend(heap_topk(cnt, 0, 20 - len(result_candidates)))\n",
    "        result[session] = np.array(result_candidates)\n",
    "        \n",
    "@nb.jit(nopython = True)\n",
    "def inference(aids, ops, row, \n",
    "              result_clicks, result_buy,\n",
    "              topk_clicks, topk_buy,\n",
    "              test_ops_weights):\n",
    "    inference_(aids, ops, row, result_clicks, topk_clicks, test_ops_weights, 0.1)\n",
    "    inference_(aids, ops, row, result_buy, topk_buy, test_ops_weights, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d2cd8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5967e084bd49e7a7bed57d2bff93c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# result place holder\n",
    "result_clicks = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "result_buy = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "for idx in tqdm(range(len(df) - len(df_test), len(df), parallel)):\n",
    "    row = df.iloc[idx:min(idx + parallel, len(df))][['session', 'idx', 'length']].values\n",
    "    inference(aids, ops, row, result_clicks, result_buy, topks[TIME_WEIGHT], topks[OP_WEIGHT], test_ops_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1426b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(223644219,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1517085, 1563459, 1309446,   16246, 1781822, 1152674, 1649869,\n",
       "        461689,  305831,  461689,  362233, 1649869, 1649869,  984597,\n",
       "       1649869,  803544, 1110941, 1190046, 1760685,  631008,  461689,\n",
       "       1190046, 1650637,  313546, 1650637,  979517,  351157, 1062149,\n",
       "       1157384, 1841388, 1469630,  305831, 1110548, 1110548,  305831,\n",
       "       1650114, 1604396, 1009750, 1800933,  495779,  394655,  495779,\n",
       "        789245,  789245,  366890,  361317, 1700164, 1755597,  789245,\n",
       "        784978], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(aids))  # product code\n",
    "print(aids.shape)\n",
    "aids[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c8e082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(223644219,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(ops))\n",
    "print(ops.shape)\n",
    "ops[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6080d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(635, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 14570947, 223643030,         1],\n",
       "       [ 14570948, 223643031,         5],\n",
       "       [ 14570949, 223643036,         1],\n",
       "       [ 14570950, 223643037,         2],\n",
       "       [ 14570951, 223643039,         1],\n",
       "       [ 14570952, 223643040,         2],\n",
       "       [ 14570953, 223643042,         1],\n",
       "       [ 14570954, 223643043,         6],\n",
       "       [ 14570955, 223643049,         1],\n",
       "       [ 14570956, 223643050,         3],\n",
       "       [ 14570957, 223643053,         1],\n",
       "       [ 14570958, 223643054,         1],\n",
       "       [ 14570959, 223643055,         2],\n",
       "       [ 14570960, 223643057,         1],\n",
       "       [ 14570961, 223643058,         1],\n",
       "       [ 14570962, 223643059,         3],\n",
       "       [ 14570963, 223643062,         9],\n",
       "       [ 14570964, 223643071,         4],\n",
       "       [ 14570965, 223643075,         1],\n",
       "       [ 14570966, 223643076,         1]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(row))  # session, idx, length\n",
    "print(row.shape)\n",
    "row[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0b867c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.typed.typeddict.Dict'>\n",
      "1671803\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779</td>\n",
       "      <td>[59625, 397451, 469285, 1253524, 737445, 17907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780</td>\n",
       "      <td>[1142000, 736515, 973453, 582732, 1502122, 889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781</td>\n",
       "      <td>[918667, 199008, 194067, 57315, 141736, 146057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899782</td>\n",
       "      <td>[834354, 779477, 595994, 740494, 889671, 98739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899783</td>\n",
       "      <td>[1817895, 607638, 1754419, 1216820, 1729553, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1\n",
       "0  12899779  [59625, 397451, 469285, 1253524, 737445, 17907...\n",
       "1  12899780  [1142000, 736515, 973453, 582732, 1502122, 889...\n",
       "2  12899781  [918667, 199008, 194067, 57315, 141736, 146057...\n",
       "3  12899782  [834354, 779477, 595994, 740494, 889671, 98739...\n",
       "4  12899783  [1817895, 607638, 1754419, 1216820, 1729553, 3..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(result_buy))\n",
    "print(len(result_buy))\n",
    "buy_df = pd.DataFrame(result_buy.items())\n",
    "buy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4818074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.typed.typeddict.Dict'>\n",
      "1671803\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779</td>\n",
       "      <td>[59625, 1253524, 737445, 438191, 731692, 17907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780</td>\n",
       "      <td>[1142000, 736515, 973453, 582732, 1502122, 889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781</td>\n",
       "      <td>[918667, 199008, 194067, 57315, 141736, 146057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899782</td>\n",
       "      <td>[834354, 595994, 740494, 889671, 987399, 77947...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899783</td>\n",
       "      <td>[1817895, 607638, 1754419, 1216820, 1729553, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1\n",
       "0  12899779  [59625, 1253524, 737445, 438191, 731692, 17907...\n",
       "1  12899780  [1142000, 736515, 973453, 582732, 1502122, 889...\n",
       "2  12899781  [918667, 199008, 194067, 57315, 141736, 146057...\n",
       "3  12899782  [834354, 595994, 740494, 889671, 987399, 77947...\n",
       "4  12899783  [1817895, 607638, 1754419, 1216820, 1729553, 3..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(result_clicks))\n",
    "print(len(result_clicks))\n",
    "clicks_df = pd.DataFrame(result_clicks.items())\n",
    "clicks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1585d6f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.typed.typeddict.Dict'>\n",
      "1837169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>543308</td>\n",
       "      <td>[723612, 423558, 589213, 138431, 798763, 75512...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>961113</td>\n",
       "      <td>[216668, 1570779, 1024163, 1543589, 1569761, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>883849</td>\n",
       "      <td>[818923, 760363, 412500, 192094, 959954, 16820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701766</td>\n",
       "      <td>[552456, 230088, 768033, 25475, 1095492, 17914...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>924751</td>\n",
       "      <td>[1283527, 226042, 780500, 667322, 168206, 1059...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                                  1\n",
       "0  543308  [723612, 423558, 589213, 138431, 798763, 75512...\n",
       "1  961113  [216668, 1570779, 1024163, 1543589, 1569761, 2...\n",
       "2  883849  [818923, 760363, 412500, 192094, 959954, 16820...\n",
       "3  701766  [552456, 230088, 768033, 25475, 1095492, 17914...\n",
       "4  924751  [1283527, 226042, 780500, 667322, 168206, 1059..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(topks[TIME_WEIGHT]))\n",
    "print(len(topks[TIME_WEIGHT]))\n",
    "time_weights_df = pd.DataFrame(topks[TIME_WEIGHT].items())\n",
    "time_weights_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67567aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.typed.typeddict.Dict'>\n",
      "1837169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>543308</td>\n",
       "      <td>[723612, 423558, 589213, 138431, 798763, 53730...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>961113</td>\n",
       "      <td>[216668, 1543589, 1570779, 234245, 1024163, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>883849</td>\n",
       "      <td>[818923, 412500, 760363, 192094, 959954, 79432...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701766</td>\n",
       "      <td>[552456, 1600159, 230088, 768033, 1095492, 179...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>924751</td>\n",
       "      <td>[780500, 226042, 1283527, 667322, 1059726, 168...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                                  1\n",
       "0  543308  [723612, 423558, 589213, 138431, 798763, 53730...\n",
       "1  961113  [216668, 1543589, 1570779, 234245, 1024163, 18...\n",
       "2  883849  [818923, 412500, 760363, 192094, 959954, 79432...\n",
       "3  701766  [552456, 1600159, 230088, 768033, 1095492, 179...\n",
       "4  924751  [780500, 226042, 1283527, 667322, 1059726, 168..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(topks[OP_WEIGHT]))\n",
    "print(len(topks[OP_WEIGHT]))\n",
    "op_weight_df = pd.DataFrame(topks[OP_WEIGHT].items())\n",
    "op_weight_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "680de35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numba.typed.typeddict.Dict'>\n",
      "1671803\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779</td>\n",
       "      <td>[59625, 397451, 469285, 1253524, 737445, 17907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780</td>\n",
       "      <td>[1142000, 736515, 973453, 582732, 1502122, 889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781</td>\n",
       "      <td>[918667, 199008, 194067, 57315, 141736, 146057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899782</td>\n",
       "      <td>[834354, 779477, 595994, 740494, 889671, 98739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899783</td>\n",
       "      <td>[1817895, 607638, 1754419, 1216820, 1729553, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1\n",
       "0  12899779  [59625, 397451, 469285, 1253524, 737445, 17907...\n",
       "1  12899780  [1142000, 736515, 973453, 582732, 1502122, 889...\n",
       "2  12899781  [918667, 199008, 194067, 57315, 141736, 146057...\n",
       "3  12899782  [834354, 779477, 595994, 740494, 889671, 98739...\n",
       "4  12899783  [1817895, 607638, 1754419, 1216820, 1729553, 3..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(result))\n",
    "print(len(result))\n",
    "result_df = pd.DataFrame(result.items())\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17e5a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = []\n",
    "op_names = [\"clicks\", \"carts\", \"orders\"]\n",
    "for result, op in zip([result_clicks, result_buy, result_buy], op_names):\n",
    "\n",
    "    sub = pd.DataFrame({\"session_type\": result.keys(), \"labels\": result.values()})\n",
    "    sub.session_type = sub.session_type.astype(str) + f\"_{op}\"\n",
    "    sub.labels = sub.labels.apply(lambda x: \" \".join(x.astype(str)))\n",
    "    subs.append(sub)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6ef195c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779_orders</td>\n",
       "      <td>59625 397451 469285 1253524 737445 1790770 731...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780_orders</td>\n",
       "      <td>1142000 736515 973453 582732 1502122 889686 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781_orders</td>\n",
       "      <td>918667 199008 194067 57315 141736 1460571 7594...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899782_orders</td>\n",
       "      <td>834354 779477 595994 740494 889671 987399 4760...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899783_orders</td>\n",
       "      <td>1817895 607638 1754419 1216820 1729553 300127 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                                             labels\n",
       "0  12899779_orders  59625 397451 469285 1253524 737445 1790770 731...\n",
       "1  12899780_orders  1142000 736515 973453 582732 1502122 889686 48...\n",
       "2  12899781_orders  918667 199008 194067 57315 141736 1460571 7594...\n",
       "3  12899782_orders  834354 779477 595994 740494 889671 987399 4760...\n",
       "4  12899783_orders  1817895 607638 1754419 1216820 1729553 300127 ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b87a668b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1671803, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sub.shape)\n",
    "type(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a7dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292335cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602ec66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19571430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c79e4ad3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'line_terminator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m sub \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(subs)\u001b[38;5;241m.\u001b[39mreset_index(drop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43msub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubmission_574.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m sub\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3551\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3509\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[0;32m   3510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_csv\u001b[39m(\n\u001b[0;32m   3511\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3532\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[0;32m   3533\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3534\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m   3536\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   3537\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   3538\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   3539\u001b[0m     compression_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression_options\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3540\u001b[0m )\n\u001b[0;32m   3541\u001b[0m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(old_arg_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline_terminator\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_arg_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlineterminator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_csv\u001b[39m(\n\u001b[0;32m   3543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3544\u001b[0m     path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3545\u001b[0m     sep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3546\u001b[0m     na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3547\u001b[0m     float_format: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Callable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3548\u001b[0m     columns: Sequence[Hashable] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3549\u001b[0m     header: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   3550\u001b[0m     index: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m-> 3551\u001b[0m     index_label: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3552\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3553\u001b[0m     encoding: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3554\u001b[0m     compression: CompressionOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3555\u001b[0m     quoting: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3556\u001b[0m     quotechar: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   3557\u001b[0m     lineterminator: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3558\u001b[0m     chunksize: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3559\u001b[0m     date_format: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3560\u001b[0m     doublequote: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   3561\u001b[0m     escapechar: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3562\u001b[0m     decimal: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3563\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3564\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3565\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3566\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3567\u001b[0m \u001b[38;5;124;03m    Write object to a comma-separated values (csv) file.\u001b[39;00m\n\u001b[0;32m   3568\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3707\u001b[0m \u001b[38;5;124;03m    >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m   3708\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3709\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1161\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(old_arg_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline_terminator\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_arg_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlineterminator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_csv\u001b[39m(\n\u001b[0;32m   1141\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1157\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;124;03m    Render dataframe as comma-separated file.\u001b[39;00m\n\u001b[1;32m-> 1161\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsvs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CSVFormatter\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path_or_buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'line_terminator'"
     ]
    }
   ],
   "source": [
    "sub = pd.concat(subs).reset_index(drop = True)\n",
    "sub.to_csv('submission_574.csv', index = False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df40827",
   "metadata": {},
   "source": [
    "## 576 CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1919aad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 6\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os, sys, pickle, glob, gc\n",
    "from collections import Counter\n",
    "import itertools\n",
    "#print('We will use RAPIDS version',cudf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "330740ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d4d32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will process 17 files, in groups of 5 and chunks of 3.\n",
      "CPU times: total: 938 ms\n",
      "Wall time: 711 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CACHE FUNCTIONS\n",
    "def read_file(f):\n",
    "    return pd.DataFrame( data_cache[f] )\n",
    "def read_file_to_cache(f):\n",
    "    df = pd.read_parquet(f)\n",
    "    df.ts = (df.ts/1000).astype('int32')\n",
    "    df['type'] = df['type'].map(type_labels).astype('int8')\n",
    "    return df\n",
    "\n",
    "# CACHE THE DATA ON CPU BEFORE PROCESSING ON GPU\n",
    "data_cache = {}\n",
    "type_labels = {'clicks':0, 'carts':1, 'orders':2}\n",
    "files = glob.glob('input/otto-chunk-data-inparquet-format/*_parquet/*')\n",
    "for f in files: data_cache[f] = read_file_to_cache(f)\n",
    "\n",
    "# CHUNK PARAMETERS\n",
    "READ_CT = 5\n",
    "CHUNK = int( np.ceil( len(files)/6 ))\n",
    "print(f'We will process {len(files)} files, in groups of {READ_CT} and chunks of {CHUNK}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e17bfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### DISK PART 1\n",
      "Processing files 0 thru 2 in groups of 5...\n",
      "0 , \n",
      "Processing files 3 thru 5 in groups of 5...\n",
      "3 , \n",
      "Processing files 6 thru 8 in groups of 5...\n",
      "6 , \n",
      "Processing files 9 thru 11 in groups of 5...\n",
      "9 , \n",
      "Processing files 12 thru 14 in groups of 5...\n",
      "12 , \n",
      "Processing files 15 thru 16 in groups of 5...\n",
      "15 , \n",
      "\n",
      "### DISK PART 2\n",
      "Processing files 0 thru 2 in groups of 5...\n",
      "0 , \n",
      "Processing files 3 thru 5 in groups of 5...\n",
      "3 , \n",
      "Processing files 6 thru 8 in groups of 5...\n",
      "6 , \n",
      "Processing files 9 thru 11 in groups of 5...\n",
      "9 , \n",
      "Processing files 12 thru 14 in groups of 5...\n",
      "12 , \n",
      "Processing files 15 thru 16 in groups of 5...\n",
      "15 , \n",
      "\n",
      "### DISK PART 3\n",
      "Processing files 0 thru 2 in groups of 5...\n",
      "0 , \n",
      "Processing files 3 thru 5 in groups of 5...\n",
      "3 , \n",
      "Processing files 6 thru 8 in groups of 5...\n",
      "6 , \n",
      "Processing files 9 thru 11 in groups of 5...\n",
      "9 , \n",
      "Processing files 12 thru 14 in groups of 5...\n",
      "12 , \n",
      "Processing files 15 thru 16 in groups of 5...\n",
      "15 , \n",
      "\n",
      "### DISK PART 4\n",
      "Processing files 0 thru 2 in groups of 5...\n",
      "0 , \n",
      "Processing files 3 thru 5 in groups of 5...\n",
      "3 , \n",
      "Processing files 6 thru 8 in groups of 5...\n",
      "6 , \n",
      "Processing files 9 thru 11 in groups of 5...\n",
      "9 , \n",
      "Processing files 12 thru 14 in groups of 5...\n",
      "12 , \n",
      "Processing files 15 thru 16 in groups of 5...\n",
      "15 , \n",
      "CPU times: total: 1min 54s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "type_weight = {0:1, 1:5, 2:4}\n",
    "\n",
    "# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "DISK_PIECES = 4\n",
    "SIZE = 1.86e6/DISK_PIECES\n",
    "\n",
    "# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "for PART in range(DISK_PIECES):\n",
    "    print()\n",
    "    print('### DISK PART',PART+1)\n",
    "    \n",
    "    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "    # => OUTER CHUNKS\n",
    "    for j in range(6):\n",
    "        a = j*CHUNK\n",
    "        b = min( (j+1)*CHUNK, len(files) )\n",
    "        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n",
    "        \n",
    "        # => INNER CHUNKS\n",
    "        for k in range(a,b,READ_CT):\n",
    "            # READ FILE\n",
    "            df = [read_file(files[k])]\n",
    "            for i in range(1,READ_CT): \n",
    "                if k+i<b: df.append( read_file(files[k+i]) )\n",
    "            df = pd.concat(df,ignore_index=True,axis=0)\n",
    "            df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "            \n",
    "            # USE TAIL OF SESSION\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['n'] = df.groupby('session').cumcount()\n",
    "            df = df.loc[df.n<30].drop('n',axis=1)\n",
    "            \n",
    "            # CREATE PAIRS\n",
    "            df = df.merge(df,on='session')\n",
    "            df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "            \n",
    "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "            \n",
    "            # ASSIGN WEIGHTS\n",
    "            df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y', 'type_y'])\n",
    "            df['wgt'] = df.type_y.map(type_weight)\n",
    "            df = df[['aid_x','aid_y','wgt']]\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "            \n",
    "            # COMBINE INNER CHUNKS\n",
    "            if k==a: tmp2 = df\n",
    "            else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k,', ',end='')\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # COMBINE OUTER CHUNKS\n",
    "        if a==0: tmp = tmp2\n",
    "        else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "        del tmp2, df\n",
    "        gc.collect()\n",
    "\n",
    "    # CONVERT MATRIX TO DICTIONARY\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "    \n",
    "    # SAVE TOP 40\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n<15].drop('n',axis=1)\n",
    "    \n",
    "    # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "    #tmp.to_pandas().to_parquet(f'top_15_carts_orders_v{VER}_{PART}.pqt')\n",
    "    tmp.to_parquet(f'top_15_carts_orders_v{VER}_{PART}.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bdc33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### DISK PART 1\n",
      "Processing files 0 thru 2 in groups of 5...\n",
      "0 , \n",
      "Processing files 3 thru 5 in groups of 5...\n",
      "3 , \n",
      "Processing files 6 thru 8 in groups of 5...\n",
      "6 , \n",
      "Processing files 9 thru 11 in groups of 5...\n",
      "9 , \n",
      "Processing files 12 thru 14 in groups of 5...\n",
      "12 , \n",
      "Processing files 15 thru 16 in groups of 5...\n",
      "15 , \n",
      "CPU times: total: 6.64 s\n",
      "Wall time: 6.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "DISK_PIECES = 1\n",
    "SIZE = 1.86e6/DISK_PIECES\n",
    "\n",
    "# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "for PART in range(DISK_PIECES):\n",
    "    print()\n",
    "    print('### DISK PART',PART+1)\n",
    "    \n",
    "    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "    # => OUTER CHUNKS\n",
    "    for j in range(6):\n",
    "        a = j*CHUNK\n",
    "        b = min( (j+1)*CHUNK, len(files) )\n",
    "        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n",
    "        \n",
    "        # => INNER CHUNKS\n",
    "        for k in range(a,b,READ_CT):\n",
    "            \n",
    "            # READ FILE\n",
    "            df = [read_file(files[k])]\n",
    "            for i in range(1,READ_CT): \n",
    "                if k+i<b: df.append( read_file(files[k+i]) )\n",
    "            df = pd.concat(df,ignore_index=True,axis=0)\n",
    "            df = df.loc[df['type'].isin([1,2])] # ONLY WANT CARTS AND ORDERS\n",
    "            df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "            \n",
    "            # USE TAIL OF SESSION\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['n'] = df.groupby('session').cumcount()\n",
    "            df = df.loc[df.n<30].drop('n',axis=1)\n",
    "            \n",
    "            # CREATE PAIRS\n",
    "            df = df.merge(df,on='session')\n",
    "            df = df.loc[ ((df.ts_x - df.ts_y).abs()< 14 * 24 * 60 * 60) & (df.aid_x != df.aid_y) ] # 14 DAYS\n",
    "            \n",
    "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "            \n",
    "            # ASSIGN WEIGHTS\n",
    "            df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y', 'type_y'])\n",
    "            df['wgt'] = 1\n",
    "            df = df[['aid_x','aid_y','wgt']]\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "            \n",
    "            # COMBINE INNER CHUNKS\n",
    "            if k==a: tmp2 = df\n",
    "            else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k,', ',end='')\n",
    "\n",
    "        print()\n",
    "        \n",
    "        # COMBINE OUTER CHUNKS\n",
    "        if a==0: tmp = tmp2\n",
    "        else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "        del tmp2, df\n",
    "        gc.collect()\n",
    "\n",
    "    # CONVERT MATRIX TO DICTIONARY\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "    \n",
    "    # SAVE TOP 40\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n<15].drop('n',axis=1)\n",
    "    \n",
    "    # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "    tmp.to_parquet(f'top_15_buy2buy_v{VER}_{PART}.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f58bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### DISK PART 1\n",
      "Processing files 0 thru 2 in groups of 5...\n",
      "0 , \n",
      "Processing files 3 thru 5 in groups of 5...\n",
      "3 , \n",
      "Processing files 6 thru 8 in groups of 5...\n",
      "6 , \n",
      "Processing files 9 thru 11 in groups of 5...\n",
      "9 , \n",
      "Processing files 12 thru 14 in groups of 5...\n",
      "12 , \n",
      "Processing files 15 thru 16 in groups of 5...\n",
      "15 , \n",
      "\n",
      "### DISK PART 2\n",
      "Processing files 0 thru 2 in groups of 5...\n",
      "0 , \n",
      "Processing files 3 thru 5 in groups of 5...\n",
      "3 , \n",
      "Processing files 6 thru 8 in groups of 5...\n",
      "6 , \n",
      "Processing files 9 thru 11 in groups of 5...\n",
      "9 , \n",
      "Processing files 12 thru 14 in groups of 5...\n",
      "12 , \n",
      "Processing files 15 thru 16 in groups of 5...\n",
      "15 , \n",
      "\n",
      "### DISK PART 3\n",
      "Processing files 0 thru 2 in groups of 5...\n",
      "0 , \n",
      "Processing files 3 thru 5 in groups of 5...\n",
      "3 , \n",
      "Processing files 6 thru 8 in groups of 5...\n",
      "6 , \n",
      "Processing files 9 thru 11 in groups of 5...\n",
      "9 , \n",
      "Processing files 12 thru 14 in groups of 5...\n",
      "12 , \n",
      "Processing files 15 thru 16 in groups of 5...\n",
      "15 , \n",
      "\n",
      "### DISK PART 4\n",
      "Processing files 0 thru 2 in groups of 5...\n",
      "0 , \n",
      "Processing files 3 thru 5 in groups of 5...\n",
      "3 , \n",
      "Processing files 6 thru 8 in groups of 5...\n",
      "6 , \n",
      "Processing files 9 thru 11 in groups of 5...\n",
      "9 , \n",
      "Processing files 12 thru 14 in groups of 5...\n",
      "12 , \n",
      "Processing files 15 thru 16 in groups of 5...\n",
      "15 , \n",
      "CPU times: total: 1min 54s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# USE SMALLEST DISK_PIECES POSSIBLE WITHOUT MEMORY ERROR\n",
    "DISK_PIECES = 4\n",
    "SIZE = 1.86e6/DISK_PIECES\n",
    "\n",
    "# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "for PART in range(DISK_PIECES):\n",
    "    print()\n",
    "    print('### DISK PART',PART+1)\n",
    "    \n",
    "    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "    # => OUTER CHUNKS\n",
    "    for j in range(6):\n",
    "        a = j*CHUNK\n",
    "        b = min( (j+1)*CHUNK, len(files) )\n",
    "        print(f'Processing files {a} thru {b-1} in groups of {READ_CT}...')\n",
    "        \n",
    "        # => INNER CHUNKS\n",
    "        for k in range(a,b,READ_CT):\n",
    "            # READ FILE\n",
    "            df = [read_file(files[k])]\n",
    "            for i in range(1,READ_CT): \n",
    "                if k+i<b: df.append( read_file(files[k+i]) )\n",
    "            df = pd.concat(df,ignore_index=True,axis=0)\n",
    "            df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "            \n",
    "            # USE TAIL OF SESSION\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['n'] = df.groupby('session').cumcount()\n",
    "            df = df.loc[df.n<30].drop('n',axis=1)\n",
    "            \n",
    "            # CREATE PAIRS\n",
    "            df = df.merge(df,on='session')\n",
    "            df = df.loc[ ((df.ts_x - df.ts_y).abs()< 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "            \n",
    "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "            \n",
    "            # ASSIGN WEIGHTS\n",
    "            df = df[['session', 'aid_x', 'aid_y','ts_x']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "            df['wgt'] = 1 + 3*(df.ts_x - 1659304800)/(1662328791-1659304800)\n",
    "            # 1659304800 : minimum timestamp\n",
    "            # 1662328791 : maximum timestamp\n",
    "            df = df[['aid_x','aid_y','wgt']]\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "            \n",
    "            # COMBINE INNER CHUNKS\n",
    "            if k==a: tmp2 = df\n",
    "            else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k,', ',end='')\n",
    "        print()\n",
    "        \n",
    "        # COMBINE OUTER CHUNKS\n",
    "        if a==0: tmp = tmp2\n",
    "        else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "        del tmp2, df\n",
    "        gc.collect()\n",
    "\n",
    "    # CONVERT MATRIX TO DICTIONARY\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "    \n",
    "    # SAVE TOP 40\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n<20].drop('n',axis=1)\n",
    "    \n",
    "    # SAVE PART TO DISK (convert to pandas first uses less memory)\n",
    "    tmp.to_parquet(f'top_20_clicks_v{VER}_{PART}.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aba92c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FREE MEMORY\n",
    "del data_cache, tmp\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20910b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data has shape (6928123, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779</td>\n",
       "      <td>59625</td>\n",
       "      <td>1661724000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780</td>\n",
       "      <td>1142000</td>\n",
       "      <td>1661724000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899780</td>\n",
       "      <td>582732</td>\n",
       "      <td>1661724058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899780</td>\n",
       "      <td>973453</td>\n",
       "      <td>1661724109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899780</td>\n",
       "      <td>736515</td>\n",
       "      <td>1661724136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session      aid          ts  type\n",
       "0  12899779    59625  1661724000     0\n",
       "1  12899780  1142000  1661724000     0\n",
       "2  12899780   582732  1661724058     0\n",
       "3  12899780   973453  1661724109     0\n",
       "4  12899780   736515  1661724136     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_test():    \n",
    "    dfs = []\n",
    "    for e, chunk_file in enumerate(glob.glob('C:/Users/ghtyu/OneDrive/Desktop/OTTO/otto_data/LB_576_Dataset_Tony/test_parquet/*')):\n",
    "        chunk = pd.read_parquet(chunk_file)\n",
    "        chunk.ts = (chunk.ts/1000).astype('int32')\n",
    "        chunk['type'] = chunk['type'].map(type_labels).astype('int8')\n",
    "        dfs.append(chunk)\n",
    "    return pd.concat(dfs).reset_index(drop=True) #.astype({\"ts\": \"datetime64[ms]\"})\n",
    "\n",
    "test_df = load_test()\n",
    "print('Test data has shape',test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db298f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are size of our 3 co-visitation matrices:\n",
      "691799 168826 691799\n",
      "CPU times: total: 24.2 s\n",
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def pqt_to_dict(df):\n",
    "    return df.groupby('aid_x').aid_y.apply(list).to_dict()\n",
    "\n",
    "# LOAD THREE CO-VISITATION MATRICES\n",
    "top_20_clicks = pqt_to_dict( pd.read_parquet(f'top_20_clicks_v{VER}_0.pqt') )\n",
    "\n",
    "for k in range(1,DISK_PIECES): \n",
    "    top_20_clicks.update( pqt_to_dict( pd.read_parquet(f'top_20_clicks_v{VER}_{k}.pqt') ) )\n",
    "\n",
    "\n",
    "top_20_buys = pqt_to_dict( pd.read_parquet(f'top_15_carts_orders_v{VER}_0.pqt') )\n",
    "\n",
    "for k in range(1,DISK_PIECES): \n",
    "    top_20_buys.update( pqt_to_dict( pd.read_parquet(f'top_15_carts_orders_v{VER}_{k}.pqt') ) )\n",
    "\n",
    "top_20_buy2buy = pqt_to_dict( pd.read_parquet(f'top_15_buy2buy_v{VER}_0.pqt') )\n",
    "\n",
    "# TOP CLICKS AND ORDERS IN TEST\n",
    "#top_clicks = test_df.loc[test_df['type']=='clicks','aid'].value_counts().index.values[:20]\n",
    "#top_orders = test_df.loc[test_df['type']=='orders','aid'].value_counts().index.values[:20]\n",
    "\n",
    "print('Here are size of our 3 co-visitation matrices:')\n",
    "print( len( top_20_clicks ), len( top_20_buy2buy ), len( top_20_buys ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a59775",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_clicks = test_df.loc[test_df['type']== 0,'aid'].value_counts().index.values[:20] \n",
    "top_carts = test_df.loc[test_df['type']== 1,'aid'].value_counts().index.values[:20]\n",
    "top_orders = test_df.loc[test_df['type']== 2,'aid'].value_counts().index.values[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab25185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type_weight_multipliers = {'clicks': 1, 'carts': 5, 'orders': 4}\n",
    "type_weight_multipliers = {0: 1, 1: 5, 2: 4}\n",
    "\n",
    "def suggest_clicks(df):\n",
    "    # USER HISTORY AIDS AND TYPES\n",
    "    aids=df.aid.tolist()\n",
    "    types = df.type.tolist()\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1] ))\n",
    "    # RERANK CANDIDATES USING WEIGHTS\n",
    "    if len(unique_aids)>=20:\n",
    "        weights=np.logspace(0.1,1,len(aids),base=2, endpoint=True)-1\n",
    "        aids_temp = Counter() \n",
    "        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n",
    "        for aid,w,t in zip(aids,weights,types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        sorted_aids = [k for k,v in aids_temp.most_common(20)]\n",
    "        return sorted_aids\n",
    "    # USE \"CLICKS\" CO-VISITATION MATRIX\n",
    "    aids2 = list(itertools.chain(*[top_20_clicks[aid] for aid in unique_aids if aid in top_20_clicks]))\n",
    "    # RERANK CANDIDATES\n",
    "    top_aids2 = [aid2 for aid2, cnt in Counter(aids2).most_common(20) if aid2 not in unique_aids]    \n",
    "    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n",
    "    # USE TOP20 TEST CLICKS\n",
    "    return result + list(top_clicks)[:20-len(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a2585b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_carts(df):\n",
    "    # User history aids and types\n",
    "    aids = df.aid.tolist()\n",
    "    types = df.type.tolist()\n",
    "    \n",
    "    # UNIQUE AIDS AND UNIQUE BUYS\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1] ))\n",
    "    df = df.loc[(df['type'] == 0)|(df['type'] == 1)]\n",
    "    unique_buys = list(dict.fromkeys(df.aid.tolist()[::-1]))\n",
    "    \n",
    "    # Rerank candidates using weights\n",
    "    if len(unique_aids) >= 20:\n",
    "        weights=np.logspace(0.5,1,len(aids),base=2, endpoint=True)-1\n",
    "        aids_temp = Counter() \n",
    "        \n",
    "        # Rerank based on repeat items and types of items\n",
    "        for aid,w,t in zip(aids,weights,types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        \n",
    "        # Rerank candidates using\"top_20_carts\" co-visitation matrix\n",
    "        aids2 = list(itertools.chain(*[top_20_buys[aid] for aid in unique_buys if aid in top_20_buys]))\n",
    "        for aid in aids2: aids_temp[aid] += 0.1\n",
    "        sorted_aids = [k for k,v in aids_temp.most_common(20)]\n",
    "        return sorted_aids\n",
    "    \n",
    "    # Use \"cart order\" and \"clicks\" co-visitation matrices\n",
    "    aids1 = list(itertools.chain(*[top_20_clicks[aid] for aid in unique_aids if aid in top_20_clicks]))\n",
    "    aids2 = list(itertools.chain(*[top_20_buys[aid] for aid in unique_aids if aid in top_20_buys]))\n",
    "    \n",
    "    # RERANK CANDIDATES\n",
    "    top_aids2 = [aid2 for aid2, cnt in Counter(aids1+aids2).most_common(20) if aid2 not in unique_aids] \n",
    "    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n",
    "    \n",
    "    # USE TOP20 TEST ORDERS\n",
    "    return result + list(top_carts)[:20-len(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ffa14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_buys(df):\n",
    "    # USER HISTORY AIDS AND TYPES\n",
    "    aids=df.aid.tolist()\n",
    "    types = df.type.tolist()\n",
    "    # UNIQUE AIDS AND UNIQUE BUYS\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1] ))\n",
    "    df = df.loc[(df['type']==1)|(df['type']==2)]\n",
    "    unique_buys = list(dict.fromkeys( df.aid.tolist()[::-1] ))\n",
    "    # RERANK CANDIDATES USING WEIGHTS\n",
    "    if len(unique_aids)>=20:\n",
    "        weights=np.logspace(0.5,1,len(aids),base=2, endpoint=True)-1\n",
    "        aids_temp = Counter() \n",
    "        # RERANK BASED ON REPEAT ITEMS AND TYPE OF ITEMS\n",
    "        for aid,w,t in zip(aids,weights,types): \n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        # RERANK CANDIDATES USING \"BUY2BUY\" CO-VISITATION MATRIX\n",
    "        aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n",
    "        for aid in aids3: aids_temp[aid] += 0.1\n",
    "        sorted_aids = [k for k,v in aids_temp.most_common(20)]\n",
    "        return sorted_aids\n",
    "    # USE \"CART ORDER\" CO-VISITATION MATRIX\n",
    "    aids2 = list(itertools.chain(*[top_20_buys[aid] for aid in unique_aids if aid in top_20_buys]))\n",
    "    # USE \"BUY2BUY\" CO-VISITATION MATRIX\n",
    "    aids3 = list(itertools.chain(*[top_20_buy2buy[aid] for aid in unique_buys if aid in top_20_buy2buy]))\n",
    "    # RERANK CANDIDATES\n",
    "    top_aids2 = [aid2 for aid2, cnt in Counter(aids2+aids3).most_common(20) if aid2 not in unique_aids] \n",
    "    result = unique_aids + top_aids2[:20 - len(unique_aids)]\n",
    "    # USE TOP20 TEST ORDERS\n",
    "    return result + list(top_orders)[:20-len(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce62ef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22min 38s\n",
      "Wall time: 22min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred_df_clicks = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(\n",
    "    lambda x: suggest_clicks(x)\n",
    ")\n",
    "\n",
    "pred_df_carts = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(\n",
    "    lambda x: suggest_carts(x)\n",
    ")\n",
    "\n",
    "pred_df_buys = test_df.sort_values([\"session\", \"ts\"]).groupby([\"session\"]).apply(\n",
    "    lambda x: suggest_buys(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a178fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_pred_df = pd.DataFrame(pred_df_clicks.add_suffix(\"_clicks\"), columns=[\"labels\"]).reset_index()\n",
    "orders_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_orders\"), columns=[\"labels\"]).reset_index()\n",
    "carts_pred_df = pd.DataFrame(pred_df_carts.add_suffix(\"_carts\"), columns=[\"labels\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19f5d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\n",
    "pred_df.columns = [\"session_type\", \"labels\"]\n",
    "pred_df[\"labels\"] = pred_df.labels.apply(lambda x: \" \".join(map(str,x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f52c0932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779_clicks</td>\n",
       "      <td>59625 1460571 485256 108125 986164 1551213 754...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780_clicks</td>\n",
       "      <td>1142000 736515 973453 582732 889686 1758603 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781_clicks</td>\n",
       "      <td>918667 199008 194067 57315 141736 754412 14605...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899782_clicks</td>\n",
       "      <td>834354 595994 740494 889671 987399 779477 8291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899783_clicks</td>\n",
       "      <td>1817895 607638 1754419 1216820 1729553 300127 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                                             labels\n",
       "0  12899779_clicks  59625 1460571 485256 108125 986164 1551213 754...\n",
       "1  12899780_clicks  1142000 736515 973453 582732 889686 1758603 12...\n",
       "2  12899781_clicks  918667 199008 194067 57315 141736 754412 14605...\n",
       "3  12899782_clicks  834354 595994 740494 889671 987399 779477 8291...\n",
       "4  12899783_clicks  1817895 607638 1754419 1216820 1729553 300127 ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c87c0e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5015409, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pred_df.shape)\n",
    "type(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb99292c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779_clicks</td>\n",
       "      <td>59625 1460571 485256 108125 986164 1551213 754...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780_clicks</td>\n",
       "      <td>1142000 736515 973453 582732 889686 1758603 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781_clicks</td>\n",
       "      <td>918667 199008 194067 57315 141736 754412 14605...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899782_clicks</td>\n",
       "      <td>834354 595994 740494 889671 987399 779477 8291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899783_clicks</td>\n",
       "      <td>1817895 607638 1754419 1216820 1729553 300127 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                                             labels\n",
       "0  12899779_clicks  59625 1460571 485256 108125 986164 1551213 754...\n",
       "1  12899780_clicks  1142000 736515 973453 582732 889686 1758603 12...\n",
       "2  12899781_clicks  918667 199008 194067 57315 141736 754412 14605...\n",
       "3  12899782_clicks  834354 595994 740494 889671 987399 779477 8291...\n",
       "4  12899783_clicks  1817895 607638 1754419 1216820 1729553 300127 ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.to_csv(\"submission_576.csv\", index=False)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e036c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
